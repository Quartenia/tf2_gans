{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to tf2_gans.blocks,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class UpsampleConv2D(Model):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 upsample_interpolation='nearest',\n",
    "                 upsample_size=(2, 2),\n",
    "                 name='upsample_conv2d',\n",
    "                 strides=(1, 1),\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(UpsampleConv2D, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.upsample = layers.UpSampling2D(size=upsample_size,\n",
    "                                            interpolation=upsample_interpolation)\n",
    "        self.conv = layers.Conv2D(filters,\n",
    "                                  kernel_size,\n",
    "                                  strides=strides,\n",
    "                                  padding=padding,\n",
    "                                  use_bias=use_bias,\n",
    "                                  kernel_initializer=kernel_initializer)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.upsample(inputs)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class DownBlock(Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 use_batch_norm=True,\n",
    "                 name='down_block',\n",
    "                 activation=layers.LeakyReLU,\n",
    "                 strides=(2, 2),\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(DownBlock, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.conv = layers.Conv2D(filters,\n",
    "                                  kernel_size,\n",
    "                                  strides=strides,\n",
    "                                  padding=padding,\n",
    "                                  use_bias=use_bias,\n",
    "                                  kernel_initializer=kernel_initializer)\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if self.use_batch_norm:\n",
    "            self.batch_norm = layers.BatchNormalization()\n",
    "\n",
    "        self.activation = activation()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv(inputs)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.batch_norm(x)\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class UpBlock(Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 use_upsample=True,\n",
    "                 upsample_interpolation='nearest',\n",
    "                 use_dropout=False,\n",
    "                 dropout_rate=0.5,\n",
    "                 name='up_block',\n",
    "                 activation=layers.ReLU,\n",
    "                 strides=(2, 2),\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(UpBlock, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.use_upsample = use_upsample\n",
    "        if use_upsample:\n",
    "            self.deconv = UpsampleConv2D(filters,\n",
    "                                         kernel_size,\n",
    "                                         upsample_interpolation=upsample_interpolation,\n",
    "                                         padding=padding,\n",
    "                                         use_bias=use_bias,\n",
    "                                         kernel_initializer=kernel_initializer)\n",
    "        else:\n",
    "            self.deconv = layers.Conv2DTranspose(filters,\n",
    "                                                 kernel_size,\n",
    "                                                 strides=strides,\n",
    "                                                 padding=padding,\n",
    "                                                 use_bias=use_bias,\n",
    "                                                 kernel_initializer=kernel_initializer)\n",
    "\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        if self.use_dropout:\n",
    "            self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.activation = activation()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.deconv(inputs)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class ResBlock(Model):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size=(3, 3),\n",
    "                 strides=(1, 1),\n",
    "                 padding_type=\"REFLECT\",\n",
    "                 use_dropout=False,\n",
    "                 dropout_rate=0.5,\n",
    "                 activation=layers.ReLU,\n",
    "                 use_bias=False,\n",
    "                 name='res_block',\n",
    "                 padding='valid',\n",
    "                 **kwargs):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.filters = filters\n",
    "        self.padding_type = padding_type\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        if use_dropout:\n",
    "            self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(filters=filters,\n",
    "                                            kernel_size=kernel_size,\n",
    "                                            strides=strides,\n",
    "                                            padding=padding,\n",
    "                                            use_bias=use_bias)\n",
    "        self.conv2 = layers.Conv2D(filters=filters,\n",
    "                                            kernel_size=kernel_size,\n",
    "                                            strides=strides,\n",
    "                                            padding=padding,\n",
    "                                            use_bias=use_bias)\n",
    "\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "\n",
    "        self.activation = activation()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.pad(inputs,\n",
    "                   [[0, 0], [1, 1], [1, 1], [0, 0]],\n",
    "                   mode=self.padding_type,\n",
    "                   constant_values=0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.activation(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x, training=training)\n",
    "        x = tf.pad(x,\n",
    "                   [[0, 0], [1, 1], [1, 1], [0, 0]],\n",
    "                   mode=self.padding_type,\n",
    "                   constant_values=0)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        return x + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_dcgan.ipynb.\n",
      "Converted blocks.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted losses.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
